# âš™ï¸ **Module 13 â€“ Advanced Cluster Management, Scaling & Resource Optimization**

---

## ğŸš€ 1. Introduction

Managing a production Kubernetes cluster requires **efficient resource usage, workload prioritization, and high availability**.

This module covers:

* Resource prioritization & Quality of Service (QoS).
* Pod scheduling strategies (NodeSelector, Affinity/Anti-Affinity, Taints/Tolerations).
* Scaling workloads (manual & auto-scaling).
* Pod Disruption Budgets (PDB).
* Topology spread and cluster de-scheduler.
* Namespaces, ResourceQuotas, and LimitRanges.

---

## ğŸ—‚ï¸ 2. Resource Prioritization & QoS

### ğŸ“– Concepts

* **QoS Classes:**

  * **Guaranteed** â†’ CPU & memory requests = limits â†’ high priority.
  * **Burstable** â†’ CPU/memory requests < limits â†’ medium priority.
  * **BestEffort** â†’ No requests/limits â†’ lowest priority.

### ğŸ”¹ Lab 1: Changing QoS for Pods

```yaml
resources:
  requests:
    memory: "512Mi"
    cpu: "500m"
  limits:
    memory: "512Mi"
    cpu: "500m"
```

Check QoS:

```bash
kubectl get pod mypod -o jsonpath='{.status.qosClass}'
```

---

## ğŸ—‚ï¸ 3. Priority Classes

* Control **pod eviction order** under resource pressure.
* Example:

```yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000000
globalDefault: false
description: "High priority pods"
```

Apply to pod:

```yaml
priorityClassName: high-priority
```

---

## ğŸ—‚ï¸ 4. Pod Scheduling Strategies

### ğŸ”¹ NodeSelector

* Schedule pods to specific nodes.

```yaml
nodeSelector:
  disktype: ssd
```

### ğŸ”¹ Affinity / Anti-Affinity

* Control pod placement based on labels.

```yaml
affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
    - labelSelector:
        matchExpressions:
        - key: app
          operator: In
          values:
          - backend
      topologyKey: "kubernetes.io/hostname"
```

### ğŸ”¹ Taints & Tolerations

* Taint nodes to restrict pod scheduling.

```yaml
kubectl taint nodes node1 key=value:NoSchedule
```

Pod toleration:

```yaml
tolerations:
- key: "key"
  operator: "Equal"
  value: "value"
  effect: "NoSchedule"
```

---

## ğŸ—‚ï¸ 5. Pod Disruption Budgets (PDB)

* Ensures minimum **availability during voluntary disruptions**.

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: backend-pdb
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: backend
```

---

## ğŸ—‚ï¸ 6. Scaling Resources

### ğŸ”¹ Manual Scaling

```bash
kubectl scale deployment myapp --replicas=5
```

### ğŸ”¹ Horizontal Pod Autoscaler (HPA)

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

---

## ğŸ—‚ï¸ 7. Topology Spread & De-scheduler

* **Topology Spread Constraints** â†’ Distribute pods across zones/nodes.

```yaml
topologySpreadConstraints:
- maxSkew: 1
  topologyKey: topology.kubernetes.io/zone
  whenUnsatisfiable: DoNotSchedule
  labelSelector:
    matchLabels:
      app: myapp
```

* **De-scheduler** â†’ Dynamically rebalance pods to improve resource usage.
* Policies: **Evict low-priority pods, balance nodes, enforce affinity/anti-affinity**.

---

## ğŸ—‚ï¸ 8. Namespaces & Resource Quotas

### ğŸ“– Concepts

* **Namespaces** â†’ Logical separation of cluster resources.
* **ResourceQuotas** â†’ Limit CPU, memory, pods per namespace.
* **LimitRanges** â†’ Set min/max resource per pod/container.

### ğŸ”¹ Lab 1: Resource Quota on Namespace

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: dev-quota
  namespace: dev
spec:
  hard:
    pods: "10"
    requests.cpu: "4"
    requests.memory: 8Gi
```

### ğŸ”¹ Lab 2: Limit Ranges

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: limits
  namespace: dev
spec:
  limits:
  - default:
      cpu: "500m"
      memory: "512Mi"
    defaultRequest:
      cpu: "200m"
      memory: "256Mi"
    type: Container
```

---

## ğŸ¯ 9. Interview & Discussion Questions

1. What are the differences between **Guaranteed, Burstable, and BestEffort QoS**?
2. How do **PriorityClasses** affect pod eviction?
3. How do **NodeSelector, Affinity, Taints, and Tolerations** work together?
4. How would you **scale applications** manually and automatically?
5. Explain **Pod Disruption Budgets** and use cases.
6. How do **ResourceQuotas and LimitRanges** help in multi-tenant clusters?
7. What is **Topology Spread**, and why is it important?
8. How does **De-scheduler** optimize cluster resources?

---

## âœ… Summary of Module 13

By completing this module, you now know how to:

* Prioritize critical workloads using **QoS and PriorityClasses**.
* Optimize pod scheduling using **NodeSelector, Affinity/Anti-Affinity, Taints/Tolerations**.
* Scale workloads using **manual and auto-scaling strategies**.
* Ensure **high availability** using Pod Disruption Budgets.
* Manage **namespaces, resource quotas, and limit ranges**.
* Balance workloads across the cluster with **Topology Spread & De-scheduler**.

ğŸ“Œ **Outcome**: You can now **efficiently manage, optimize, and scale production Kubernetes clusters** for reliability and performance.

---

If you want, I can continue with **Module 14 â€“ Logging, Monitoring, Auditing & Observability with Prometheus, Grafana, Fluentd, Falco, and EFK Stack** next in the same professional format. Do you want me to proceed?

â€”-------------------------------------------

Perfect âœ… Letâ€™s move on to **Module 14 â€“ Logging, Monitoring, Auditing & Observability in Kubernetes**.

---

# ğŸ“Š **Module 14 â€“ Logging, Monitoring, Auditing & Observability**

---

## ğŸš€ 1. Introduction

Observability in Kubernetes is critical for **proactive monitoring, troubleshooting, and security**.

Key components:

* **Metrics** â†’ CPU, memory, network usage.
* **Logs** â†’ Application & system events.
* **Tracing** â†’ Request flow across microservices.
* **Security monitoring** â†’ Detect abnormal behavior.

This module covers:

* Prometheus & Grafana for metrics.
* Logging solutions (Fluentd, EFK/ELK).
* Auditing & security monitoring (Falco).
* Visualization & distributed tracing.

---

## ğŸ—‚ï¸ 2. Monitoring with Prometheus & Grafana

### ğŸ“– Concepts

* **Prometheus** â†’ Time-series metrics collection.
* **Grafana** â†’ Visualize metrics dashboards.
* **Alertmanager** â†’ Sends alerts on metric thresholds.

---

### ğŸ”¹ Lab 1: Install Prometheus & Grafana

```bash
kubectl create namespace monitoring
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install prometheus prometheus-community/kube-prometheus-stack -n monitoring
```

Verify:

```bash
kubectl get pods -n monitoring
```

---

### ğŸ”¹ Lab 2: Visualize Metrics in Grafana

* Port-forward Grafana:

```bash
kubectl port-forward svc/prometheus-grafana 3000:80 -n monitoring
```

* Default credentials: admin/admin
* Import dashboards: Kubernetes cluster metrics, Pod CPU/Memory, Node metrics

---

### ğŸ”¹ Lab 3: Configure Alerts

* Create PrometheusRule for high CPU usage:

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: high-cpu
  namespace: monitoring
spec:
  groups:
  - name: cpu-alert
    rules:
    - alert: HighCPUUsage
      expr: sum(rate(container_cpu_usage_seconds_total[2m])) by (pod) > 0.8
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "High CPU usage detected"
```

---

## ğŸ—‚ï¸ 3. Logging with EFK (Elasticsearch, Fluentd, Kibana)

### ğŸ“– Concepts

* **Fluentd** â†’ Collects logs from pods & nodes.
* **Elasticsearch** â†’ Centralized log storage & indexing.
* **Kibana** â†’ Visualize and search logs.

### ğŸ”¹ Lab 4: Deploy EFK Stack

```bash
kubectl apply -f https://raw.githubusercontent.com/elastic/cloud-on-k8s/master/config/samples/efk-stack.yaml
```

* Verify logs are indexed and searchable in Kibana.

---

## ğŸ—‚ï¸ 4. Security Monitoring with Falco

### ğŸ“– Concepts

* Falco detects **abnormal container behavior** using syscall rules.
* Can alert on **unauthorized access, process execution, file changes**.

### ğŸ”¹ Lab 5: Install Falco

```bash
kubectl apply -f https://raw.githubusercontent.com/falcosecurity/falco/master/kubernetes/falco-daemonset.yaml
kubectl get pods -n falco
```

* Create custom rules for security policies.

---

## ğŸ—‚ï¸ 5. Auditing in Kubernetes

* Enable **Audit Logs** for cluster events (API access, changes, failed requests).
* Configure `audit-policy.yaml`:

```yaml
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
- level: Metadata
  verbs: ["create", "update", "delete"]
  resources:
  - group: ""
    resources: ["pods", "services"]
```

* Enable auditing in kube-apiserver with:

```bash
--audit-policy-file=/etc/kubernetes/audit-policy.yaml
--audit-log-path=/var/log/k8s-audit/audit.log
```

---

## ğŸ—‚ï¸ 6. Distributed Tracing

* **Jaeger** â†’ Traces requests across microservices.
* **Kiali** â†’ Visualize service communication & mesh metrics.

### ğŸ”¹ Lab 6: Install Jaeger & Kiali

```bash
kubectl apply -f https://github.com/istio/istio/releases/download/1.19.1/jaeger.yaml
kubectl apply -f https://github.com/istio/istio/releases/download/1.19.1/kiali.yaml
```

* Access Jaeger UI:

```bash
kubectl port-forward svc/jaeger-query 16686:16686
```

* Access Kiali UI:

```bash
kubectl port-forward svc/kiali 20001:20001
```

---

## ğŸ¯ 7. Interview & Discussion Questions

1. Explain **Prometheus and Grafana** workflow for monitoring.
2. How does **EFK stack** centralize logs in Kubernetes?
3. What is **Falco**, and how is it used for security?
4. How do you enable **Kubernetes auditing**, and what events are important?
5. What is **distributed tracing**, and how do **Jaeger and Kiali** help?
6. How do you configure **alerts and notifications** for production clusters?

---

## âœ… Summary of Module 14

By completing this module, you now know how to:

* Collect, store, and visualize metrics using **Prometheus & Grafana**.
* Centralize and search logs with **Fluentd + Elasticsearch + Kibana (EFK)**.
* Implement **security monitoring** using Falco.
* Enable **Kubernetes auditing** for compliance and troubleshooting.
* Perform **distributed tracing** using Jaeger and visualize service communication with Kiali.

ğŸ“Œ **Outcome**: You can now **monitor, audit, and secure Kubernetes clusters and applications effectively**, ensuring production reliability and observability.

